---
title: "Decoding EEG Rhythms During Action Observation, Motor Imagery, and Execution for Standing and Sitting"
collection: publications
category: manuscripts
permalink: /publication/2020-06-30-sit2stand
excerpt: 'This study explores EEG rhythm decoding during action observation (AO), motor imagery (MI), and motor execution (ME) for sit-to-stand and stand-to-sit transitions'
date: 2020-06-30
venue: 'Journal 1'
slidesurl: 'https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9130151'
paperurl: 'https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9130151'
citation: 'R. Chaisaen et al., &quot;Decoding EEG Rhythms During Action Observation, Motor Imagery, and Execution for Standing and Sitting,&quot; in <i>IEEE Sensors Journal,</i>. vol. 20, no. 22, pp. 13776-13786, 15 Nov.15, 2020, doi: 10.1109/JSEN.2020.3005968.'
---
Event-related desynchronization and synchronization (ERD/S) and movement-related cortical potential (MRCP) play an important role in brain-computer interfaces (BCI) for lower limb rehabilitation, particularly in standing and sitting. However, little is known about the differences in the cortical activation between standing and sitting, especially how the brain’s intention modulates the pre-movement sensorimotor rhythm as they do for switching movements. In this study, we aim to investigate the decoding of continuous EEG rhythms during action observation (AO), motor imagery (MI), and motor execution (ME) for the actions of standing and sitting. We developed a behavioral task in which participants were instructed to perform both AO and MI/ME in regard to the transitioning actions of sit-to-stand and stand-to-sit. Our results demonstrated that the ERD was prominent during AO, whereas ERS was typical during MI at the alpha band across the sensorimotor area. A combination of the filter bank common spatial pattern (FBCSP) and support vector machine (SVM) for classification was used for both offline and classifier testing analyses. The offline analysis indicated the classification of AO and MI providing the highest mean accuracy at 82.73±2.54% in the stand-to-sit transition. By applying the classifier testing analysis, we demonstrated the higher performance of decoding neural intentions from the MI paradigm in comparison to the ME paradigm. These observations led us to the promising aspect of using our developed tasks based on the integration of both AO and MI to build future exoskeleton-based rehabilitation systems.
